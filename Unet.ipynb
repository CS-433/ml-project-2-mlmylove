{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "266beabf",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2616d60",
   "metadata": {},
   "source": [
    "Please install cuda on your device if you have a GPU available.  \n",
    "This line in the miniconda prompt worked for me: conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0  \n",
    "You can refer to this: https://stackoverflow.com/questions/45662253/can-i-run-keras-model-on-gpu  \n",
    "And also this: https://www.tensorflow.org/install/pip#linux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d52e4d1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840370a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # Makes visible cuda devices, -1 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fed192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import tensorflow as tf\n",
    "print(f'This value has to be at most 2.10.x ---> {tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014a4fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will print logs and cannot be disabled (except restart). Run only to check that GPU is enabled\n",
    "# tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4e06f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make use of GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# with tf.device('/cpu:0'): Force CPU utilization instead of GPU\n",
    "# This code should run on the GPU, you can see it by uncommenting the code in the previous cell\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afc5e2d",
   "metadata": {},
   "source": [
    "## Unet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95abb6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unet model from https://github.com/zhixuhao/unet/blob/master/model.py\n",
    "\n",
    "# TODO TRY F1 AS METRIC IN MODEL.COMPILE\n",
    "# TODO TRY OTHER ACTIVATION -> extract in arg of function\n",
    "\n",
    "def unet(input_size, verbose = False):\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    \n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs = inputs, outputs = conv10, name='Unet')\n",
    "\n",
    "    model.compile(optimizer = Adam(learning_rate = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    if verbose:\n",
    "        model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd5f827",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b8756",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIRECTORY_PATH = './training/'\n",
    "TRAIN_IMAGES_PATH = TRAIN_DIRECTORY_PATH + 'images/'\n",
    "TRAIN_GROUNDTRUTH_PATH = TRAIN_DIRECTORY_PATH + 'groundtruth/'\n",
    "\n",
    "TEST_DIRECTORY_PATH = './test_set_images/'\n",
    "TEST_IMAGES_PATH = [TEST_DIRECTORY_PATH + \"test_\" + str(i) + \"/\" for i in range(1,51)]\n",
    "\n",
    "PATCH_SIZE = 96\n",
    "NUMBER_IMAGES_TRAINING = 100 # Not used\n",
    "NUMBER_CHANNELS_INPUT = 3\n",
    "\n",
    "MODEL = unet((PATCH_SIZE, PATCH_SIZE, NUMBER_CHANNELS_INPUT), verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af15c832",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8664d194",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "\n",
    "for file in os.listdir(TRAIN_IMAGES_PATH):\n",
    "    img = plt.imread(TRAIN_IMAGES_PATH + file)\n",
    "    img_split = split_into_patches(img, PATCH_SIZE)\n",
    "    train_images.append(img_split)\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "# Below, this merges the first two dimensions. Instead of having x elements of y patches, we have x*y patches.\n",
    "train_images = combine_dims(train_images, start = 0, count = 2)\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdf1f89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "\n",
    "for file in os.listdir(TRAIN_GROUNDTRUTH_PATH):\n",
    "    img = plt.imread(TRAIN_GROUNDTRUTH_PATH + file)\n",
    "    img_split = split_into_patches(img, PATCH_SIZE)\n",
    "    train_labels.append(img_split)\n",
    "    \n",
    "train_labels = np.array(train_labels)\n",
    "train_labels = combine_dims(train_labels, start = 0, count = 2)\n",
    "# Below, this adds a dimension at the end, such that the image is of size x*x*1, where 1 is the grayscale value of the pixel\n",
    "train_labels = train_labels[:, :, :, np.newaxis]\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820cdaf1",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33a7fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "test_ids = []\n",
    "\n",
    "for directory in TEST_IMAGES_PATH:\n",
    "    for file in os.listdir(directory):\n",
    "        test_ids.append(file)\n",
    "        img = plt.imread(directory + file)\n",
    "        img_split = split_into_patches(img, PATCH_SIZE)\n",
    "        test_images.append(img_split)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "# Below, this merges the first two dimensions. Instead of having x elements of y patches, we have x*y patches.\n",
    "test_images = combine_dims(test_images, start = 0, count = 2)\n",
    "print(test_images.shape)\n",
    "\n",
    "test_ids = [x.split(\".\")[0] for x in test_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab27d0e3",
   "metadata": {},
   "source": [
    "### Split for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8967888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO check other test_size fractions\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_images, train_labels, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b66ac3",
   "metadata": {},
   "source": [
    "## Call model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72620bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./check_points/unet_model\"\n",
    "\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=7, monitor='val_loss'),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1, save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717a1e99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MODEL.fit(X_train, y_train, verbose=1, epochs=50, validation_data=(X_test, y_test), shuffle=True, callbacks=callbacks)\n",
    "MODEL.save(\"./models/unet_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f616a6f2",
   "metadata": {},
   "source": [
    "### Instead of running the model you can fetch it from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ea58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('./models/unet_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74971bb9",
   "metadata": {},
   "source": [
    "### Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd73ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO try other threshold for the prediction\n",
    "fig, ax = plt.subplots(1,3)\n",
    "\n",
    "ax[0].imshow(X_train[6])\n",
    "ax[0].title.set_text('Train image')\n",
    "ax[1].imshow(y_train[6], cmap=\"gray\")\n",
    "ax[1].title.set_text('Groundtruth')\n",
    "\n",
    "prediction = loaded_model.predict(X_train[6][np.newaxis, :, :, :]) # Need to add an axis in front as mode expects batch\n",
    "prediction = (prediction > 0.5).astype(np.uint8) # Transforms continuous values into 0-1\n",
    "\n",
    "ax[2].imshow(prediction[0], cmap=\"gray\")\n",
    "ax[2].title.set_text('Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d50be7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_you_want_to_see = 2\n",
    "\n",
    "fig, ax = plt.subplots(7,7)\n",
    "for i in range(7*image_you_want_to_see,7*image_you_want_to_see + 7):\n",
    "    for j in range(7):\n",
    "        ax[i-image_you_want_to_see*7,j].imshow(test_images[7*i + j])\n",
    "\n",
    "fig1, ax1 = plt.subplots(7,7)\n",
    "for i in range(7*image_you_want_to_see,7*image_you_want_to_see + 7):\n",
    "    for j in range(7):\n",
    "        prediction = loaded_model.predict(test_images[7*i + j][np.newaxis, :, :, :], verbose = False)\n",
    "        prediction = (prediction > 0.2).astype(np.uint8)\n",
    "        ax1[i-image_you_want_to_see*7,j].imshow(prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b346853",
   "metadata": {},
   "source": [
    "## Save submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52d95e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_predictions = loaded_model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097564c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = []\n",
    "# The constants with _SIDE mean how many patches fit per image in one dimension (one side)\n",
    "TEST_IMAGE_LENGTH = 608\n",
    "PATCHES_PER_IMAGE_SIDE = math.ceil(TEST_IMAGE_LENGTH/PATCH_SIZE)\n",
    "PATCHES_PER_IMAGE = PATCHES_PER_IMAGE_SIDE**2\n",
    "SUBIMAGES_PER_PATCH_SIDE = PATCH_SIZE/16\n",
    "for i, pred in enumerate(test_predictions):\n",
    "    img_id = test_ids[i//PATCHES_PER_IMAGE]\n",
    "    # Format the image id\n",
    "    id = img_id.split('_')[1].zfill(3)\n",
    "    # Make sure the patch size is a multiple of 16 otherwise this line won't work\n",
    "    preds = split_into_patches(pred, 16)\n",
    "    for j, img in enumerate(preds):\n",
    "        # Calculate the index of each subimage (in terms of pixels)\n",
    "        x = 16*(SUBIMAGES_PER_PATCH_SIDE*((i % PATCHES_PER_IMAGE) % PATCHES_PER_IMAGE_SIDE) + j % SUBIMAGES_PER_PATCH_SIDE)\n",
    "        y = 16*(SUBIMAGES_PER_PATCH_SIDE*((i % PATCHES_PER_IMAGE) // PATCHES_PER_IMAGE_SIDE) + j // SUBIMAGES_PER_PATCH_SIDE)\n",
    "        # Don't add the padding predictions\n",
    "        if x < TEST_IMAGE_LENGTH and y < TEST_IMAGE_LENGTH:\n",
    "            # For now we calculate the average over all the pixels and check if it's above 0.5\n",
    "            submission.append((f\"{id}_{x:.0f}_{y:.0f}\", 1 if img.mean() > 0.5 else 0))\n",
    "np.savetxt(\"predictions.csv\", np.asarray(submission), fmt=\"%s\", delimiter=\",\", newline=\"\\n\", header=\"id,prediction\", comments=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf8ed43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
