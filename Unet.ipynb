{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "266beabf",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2616d60",
   "metadata": {},
   "source": [
    "Please install cuda on your device if you have a GPU available.  \n",
    "This line in the miniconda prompt worked for me: conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0  \n",
    "You can refer to this: https://stackoverflow.com/questions/45662253/can-i-run-keras-model-on-gpu  \n",
    "And also this: https://www.tensorflow.org/install/pip#linux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d52e4d1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840370a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # Makes visible cuda devices, -1 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fed192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "from models import *\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import tensorflow as tf\n",
    "print(f'This value has to be at most 2.10.x ---> {tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014a4fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will print logs and cannot be disabled (except restart). Run only to check that GPU is enabled\n",
    "#tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4e06f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make use of GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# with tf.device('/cpu:0'): Force CPU utilization instead of GPU\n",
    "# This code should run on the GPU, you can see it by uncommenting the code in the previous cell\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd5f827",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da74d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run models.py # If you have error of XXX not found below, try this\n",
    "%run helpers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b8756",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIRECTORY_PATH = './training/'\n",
    "TRAIN_IMAGES_PATH = TRAIN_DIRECTORY_PATH + 'images/'\n",
    "TRAIN_GROUNDTRUTH_PATH = TRAIN_DIRECTORY_PATH + 'groundtruth/'\n",
    "\n",
    "NEW_TRAIN_DIRECTORY_PATH = './new_training/'\n",
    "NEW_TRAIN_IMAGES_PATH = NEW_TRAIN_DIRECTORY_PATH + 'images/'\n",
    "NEW_TRAIN_GROUNDTRUTH_PATH = NEW_TRAIN_DIRECTORY_PATH + 'groundtruth/'\n",
    "\n",
    "TEST_DIRECTORY_PATH = './test_set_images/'\n",
    "TEST_IMAGES_PATH = [TEST_DIRECTORY_PATH + \"test_\" + str(i) + \"/\" for i in range(1,51)]\n",
    "\n",
    "PATCH_SIZE = 96\n",
    "NUMBER_NEW_TRAINING_TO_TAKE = 0 # Used\n",
    "NUMBER_CHANNELS_INPUT = 3\n",
    "BATCH_SIZE = 64 # Put 16 to avoid burning your laptop\n",
    "\n",
    "MODEL_FUNCTION = fat_unet # Just implement your model in models.py and change this\n",
    "MODEL = MODEL_FUNCTION((PATCH_SIZE, PATCH_SIZE, NUMBER_CHANNELS_INPUT), verbose = False)\n",
    "\n",
    "CHECKPOINT_PATH = \"./check_points/\" + str(MODEL_FUNCTION.__name__)\n",
    "SAVE_MODEL_PATH = \"./models/\" + str(MODEL_FUNCTION.__name__) + \".h5\"\n",
    "\n",
    "RANDOM = np.random.randint(69)\n",
    "\n",
    "tf.random.set_seed(RANDOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225a6aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from local models folder\n",
    "#MODEL = tf.keras.models.load_model(SAVE_MODEL_PATH, custom_objects={'get_f1': get_f1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af15c832",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8664d194",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "\n",
    "for file in tqdm(os.listdir(TRAIN_IMAGES_PATH), total=len(os.listdir(TRAIN_IMAGES_PATH))):\n",
    "    img = plt.imread(TRAIN_IMAGES_PATH + file)\n",
    "    img_split = split_into_patches(img, PATCH_SIZE)\n",
    "    train_images.append(img_split)\n",
    "\n",
    "# New images\n",
    "new_train_images = []\n",
    "for num, file in enumerate(os.listdir(NEW_TRAIN_IMAGES_PATH)):\n",
    "    if num == NUMBER_NEW_TRAINING_TO_TAKE:\n",
    "        break\n",
    "    img = plt.imread(NEW_TRAIN_IMAGES_PATH + file)\n",
    "    img_split = split_into_patches(img, PATCH_SIZE)\n",
    "    new_train_images.append(img_split)\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "new_train_images = np.array(new_train_images)\n",
    "\n",
    "# Below, this merges the first two dimensions. Instead of having x elements of y patches, we have x*y patches.\n",
    "train_images = combine_dims(train_images, start = 0, count = 2)\n",
    "new_train_images = combine_dims(new_train_images, start = 0, count = 2)\n",
    "print(f'Base train shape: {train_images.shape}')\n",
    "print(f'New train shape: {new_train_images.shape}')\n",
    "\n",
    "# Add new training\n",
    "if NUMBER_NEW_TRAINING_TO_TAKE:\n",
    "    train_images = np.concatenate((train_images, new_train_images))\n",
    "    print(f'Concatenated train shape: {train_images.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdf1f89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "\n",
    "for file in tqdm(os.listdir(TRAIN_GROUNDTRUTH_PATH),total=len(os.listdir(TRAIN_GROUNDTRUTH_PATH))):\n",
    "    img = plt.imread(TRAIN_GROUNDTRUTH_PATH + file)\n",
    "    img_split = split_into_patches(img, PATCH_SIZE)\n",
    "    train_labels.append(img_split)\n",
    "\n",
    "# New images\n",
    "new_train_labels = []\n",
    "for num, file in enumerate(os.listdir(NEW_TRAIN_GROUNDTRUTH_PATH)):\n",
    "    if num == NUMBER_NEW_TRAINING_TO_TAKE:\n",
    "        break\n",
    "    img = plt.imread(NEW_TRAIN_GROUNDTRUTH_PATH + file)\n",
    "    img_split = split_into_patches(img, PATCH_SIZE)\n",
    "    new_train_labels.append(img_split)\n",
    "    \n",
    "train_labels = np.array(train_labels)\n",
    "new_train_labels = np.array(new_train_labels)\n",
    "\n",
    "train_labels = combine_dims(train_labels, start = 0, count = 2)\n",
    "new_train_labels = combine_dims(new_train_labels, start = 0, count = 2)\n",
    "# Below, this adds a dimension at the end, such that the image is of size x*x*1, where 1 is the grayscale value of the pixel\n",
    "train_labels = train_labels[:, :, :, np.newaxis]\n",
    "if NUMBER_NEW_TRAINING_TO_TAKE:\n",
    "    new_train_labels = new_train_labels[:, :, :, np.newaxis]\n",
    "print(train_labels.shape)\n",
    "print(new_train_labels.shape)\n",
    "\n",
    "# Add new training\n",
    "if NUMBER_NEW_TRAINING_TO_TAKE:\n",
    "    train_labels = np.concatenate((train_labels, new_train_labels))\n",
    "    print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820cdaf1",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33a7fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "test_ids = []\n",
    "\n",
    "for directory in tqdm(TEST_IMAGES_PATH, total=len(TEST_IMAGES_PATH)):\n",
    "    for file in os.listdir(directory):\n",
    "        test_ids.append(file)\n",
    "        img = plt.imread(directory + file)\n",
    "        img_split = split_into_patches(img, PATCH_SIZE)\n",
    "        test_images.append(img_split)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "# Below, this merges the first two dimensions. Instead of having x elements of y patches, we have x*y patches.\n",
    "test_images = combine_dims(test_images, start = 0, count = 2)\n",
    "print(test_images.shape)\n",
    "\n",
    "test_ids = [x.split(\".\")[0] for x in test_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab27d0e3",
   "metadata": {},
   "source": [
    "### Split for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8967888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_images, train_labels, test_size = 0.20, random_state = RANDOM)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b66ac3",
   "metadata": {},
   "source": [
    "## Call model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72620bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss'),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=CHECKPOINT_PATH, save_weights_only=True, verbose=1, save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717a1e99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#MODEL = tf.keras.models.load_model(SAVE_MODEL_PATH, custom_objects={'get_f1': get_f1}) # Once you run the model once, you can train more by running this cell again\n",
    "train_gen = DataGenerator(X_train, y_train, BATCH_SIZE)\n",
    "test_gen = DataGenerator(X_test, y_test, BATCH_SIZE)\n",
    "\n",
    "MODEL.fit(train_gen, verbose=True, epochs=100, validation_data=test_gen, shuffle=True, callbacks=callbacks)\n",
    "MODEL.save(SAVE_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f616a6f2",
   "metadata": {},
   "source": [
    "### Instead of running the model you can fetch it from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ea58f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL.load_weights(CHECKPOINT_PATH) #Loads best model\n",
    "#print(MODEL.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74971bb9",
   "metadata": {},
   "source": [
    "### Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd73ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_you_want_to_see = 1\n",
    "pred_threshold = 0.2\n",
    "\n",
    "fig, ax = plt.subplots(1,3)\n",
    "\n",
    "ax[0].imshow(X_train[patch_you_want_to_see])\n",
    "ax[0].title.set_text('Train image')\n",
    "ax[1].imshow(y_train[patch_you_want_to_see], cmap=\"gray\")\n",
    "ax[1].title.set_text('Groundtruth')\n",
    "\n",
    "prediction = MODEL.predict(X_train[patch_you_want_to_see][np.newaxis, :, :, :]) # Need to add an axis in front as mode expects batch\n",
    "prediction = (prediction > pred_threshold).astype(np.uint8) # Transforms continuous values into 0-1\n",
    "\n",
    "ax[2].imshow(prediction[0], cmap=\"gray\")\n",
    "ax[2].title.set_text('Prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8801be9",
   "metadata": {},
   "source": [
    "### Check test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8898049-652b-4bc5-bad7-ab4a8a001b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_you_want_to_see = 1\n",
    "patch_side_len = 7 # DEPENDS ON SIZE OF IMAGE AND PATCHSIZE\n",
    "pred_threshold = 0.5\n",
    "\n",
    "test_image_side_len = patch_side_len * PATCH_SIZE\n",
    "reconstructed_image = np.zeros((test_image_side_len, test_image_side_len, 3))\n",
    "reconstructed_gt = np.zeros((test_image_side_len, test_image_side_len, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8acda6d-79bc-4e44-af95-fc906ff76873",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "for i in range(patch_side_len*image_you_want_to_see,patch_side_len*image_you_want_to_see + patch_side_len):\n",
    "    for j in range(patch_side_len):\n",
    "        reconstructed_image[(i-patch_side_len*image_you_want_to_see)*PATCH_SIZE : (i-patch_side_len*image_you_want_to_see)*PATCH_SIZE + PATCH_SIZE, j*PATCH_SIZE : j*PATCH_SIZE + PATCH_SIZE] = test_images[patch_side_len*i + j]\n",
    "\n",
    "ax[0].imshow(reconstructed_image)\n",
    "\n",
    "for i in range(patch_side_len*image_you_want_to_see,patch_side_len*image_you_want_to_see + patch_side_len):\n",
    "    for j in range(patch_side_len):\n",
    "        prediction = MODEL.predict(test_images[patch_side_len*i + j][np.newaxis, :, :, :], verbose = False)\n",
    "        prediction = (prediction > pred_threshold).astype(np.uint8)\n",
    "        reconstructed_gt[(i-patch_side_len*image_you_want_to_see)*PATCH_SIZE : (i-patch_side_len*image_you_want_to_see)*PATCH_SIZE + PATCH_SIZE, j*PATCH_SIZE : j*PATCH_SIZE + PATCH_SIZE] = prediction[0]\n",
    "\n",
    "ax[1].imshow(reconstructed_gt, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b346853",
   "metadata": {},
   "source": [
    "## Save submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf6dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL = tf.keras.models.load_model(SAVE_MODEL_PATH, custom_objects={'get_f1': get_f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52d95e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = MODEL.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097564c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_thres = 0.2\n",
    "prediction_to_csv(test_predictions, test_ids, PATCH_SIZE, submission_thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caa8cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
