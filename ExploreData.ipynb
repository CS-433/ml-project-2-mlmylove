{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ce48c91",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2185c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run mask_to_submission # This generates dummy_submission.csv which is needed to import submission_to_mask w/o errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36b7a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask_to_submission import *\n",
    "from submission_to_mask import *\n",
    "from helpers import *\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd8eeb2",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18499b64",
   "metadata": {},
   "source": [
    "## Training images and ground truth\n",
    "#### Just a peek at what the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a41c5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 11 ,8\n",
    "\n",
    "img_train_1 = mpimg.imread('training/images/satImage_001.png')\n",
    "img_gt_1 = mpimg.imread('training/groundtruth/satImage_001.png')\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "\n",
    "ax[0].imshow(img_train_1)\n",
    "ax[0].title.set_text('Train image 1')\n",
    "ax[1].imshow(img_gt_1, cmap=\"gray\")\n",
    "ax[1].title.set_text('Groundtruth 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb304451",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb3f619",
   "metadata": {},
   "source": [
    "## Split image into patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5e75b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_image_1 = img_train_1[200:216, 200:216]\n",
    "sub_image_2 = img_train_1[240:256, 260:276]\n",
    "fig, ax = plt.subplots(1,2)\n",
    "\n",
    "ax[0].imshow(sub_image_1)\n",
    "ax[0].title.set_text('Train subimage 1, road')\n",
    "ax[1].imshow(sub_image_2)\n",
    "ax[1].title.set_text('Train subimage 2, not road')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceeb397",
   "metadata": {},
   "source": [
    "#### Basically we cannot train on independent 16x16 images, we need to train on the whole image/a bigger patch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db5d3d3",
   "metadata": {},
   "source": [
    "#### As we only have 100 train images, we can split those images into patches of a smaller size. Size is restricted to a multiple of 16 (for the submission) that must divide 400 (image length and width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fc7fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#See function split_into_patches(img, patchsize) in helpers.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f728101",
   "metadata": {},
   "source": [
    "#### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d1fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "patchsize = 80\n",
    "si = split_into_patches(img_train_1, patchsize)\n",
    "\n",
    "fig, ax = plt.subplots(5,5) # Works for patchsize = 80\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        ax[i,j].imshow(si[5*i + j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b9b54a",
   "metadata": {},
   "source": [
    "#### Same can be applied to ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8e2c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "patchsize = 80\n",
    "si = split_into_patches(img_gt_1, patchsize)\n",
    "\n",
    "fig, ax = plt.subplots(5,5) # Works for patchsize = 80\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        ax[i,j].imshow(si[5*i + j], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8d934c",
   "metadata": {},
   "source": [
    "### Random patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8faa75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_random_n_patches(img, n, patchsize, tlcs=[]):\n",
    "    assert len(tlcs) == 0 or len(tlcs) == n, \"Invalid top-left corners list. Must be either empty or have length n\"\n",
    "    tlcs_empty = len(tlcs) == 0\n",
    "    \n",
    "    sub_images = []\n",
    "    width_valid_tlc = img.shape[0] - patchsize\n",
    "    height_valid_tlc = img.shape[1] - patchsize\n",
    "    \n",
    "    for i in range(n):\n",
    "        if tlcs_empty: # This allows us to use this argument to fetch corresponding ground truth\n",
    "            tlc = np.random.randint(0, width_valid_tlc), np.random.randint(0, height_valid_tlc)\n",
    "            tlcs.append(tlc)\n",
    "        sub_images.append(img[tlcs[i][0]:tlcs[i][0]+patchsize,tlcs[i][1]:tlcs[i][1]+patchsize])\n",
    "            \n",
    "    return np.array(sub_images), tlcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13a16c8",
   "metadata": {},
   "source": [
    "#### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64092939",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "si_rand, tlcs_rand = split_into_random_n_patches(img_train_1, 4*4, patchsize) # Notice tlcs is *not* specified\n",
    "\n",
    "fig, ax = plt.subplots(4, 4)\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        ax[i,j].title.set_text(\"TLC:\" + str(tlcs_rand[4*i + j]))\n",
    "        ax[i,j].imshow(si_rand[4*i + j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3518c2fc",
   "metadata": {},
   "source": [
    "#### Ground truth can be computed using optional argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56683253",
   "metadata": {},
   "outputs": [],
   "source": [
    "si_rand, tlcs_rand = split_into_random_n_patches(img_gt_1, 4*4, patchsize, tlcs_rand) # Notice tlcs is specified\n",
    "\n",
    "fig, ax = plt.subplots(4, 4)\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        ax[i,j].title.set_text(\"TLC:\" + str(tlcs_rand[4*i + j]))\n",
    "        ax[i,j].imshow(si_rand[4*i + j], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be26cf",
   "metadata": {},
   "source": [
    "## Rotate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc668d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_train_1_0 = img_train_1\n",
    "img_train_1_90 = cv.rotate(img_train_1, cv.ROTATE_90_CLOCKWISE)\n",
    "img_train_1_180 = cv.rotate(img_train_1, cv.ROTATE_180)\n",
    "img_train_1_270 = cv.rotate(img_train_1, cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "array_rotations = [img_train_1_0, img_train_1_90, img_train_1_180, img_train_1_270]\n",
    "\n",
    "fig, ax = plt.subplots(1,4)\n",
    "for i in range(4):\n",
    "    ax[i].title.set_text(str(i*90))\n",
    "    ax[i].imshow(array_rotations[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc30b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
